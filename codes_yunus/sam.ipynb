{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:37:27,002 [INFO] WRITING LOG OUTPUT TO /Users/demir/.cellpose/run.log\n",
      "2025-05-06 15:37:27,002 [INFO] \n",
      "cellpose version: \t3.1.1.1 \n",
      "platform:       \tdarwin \n",
      "python version: \t3.10.17 \n",
      "torch version:  \t2.6.0\n",
      "2025-05-06 15:37:27,046 [INFO] ** TORCH MPS version installed and working. **\n",
      "2025-05-06 15:37:27,050 [INFO] ** TORCH MPS version installed and working. **\n",
      "2025-05-06 15:37:27,050 [INFO] >>>> using GPU (MPS)\n",
      "2025-05-06 15:37:27,184 [INFO] >>>> no model weights loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cellpose import models, core, io, plot\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "\n",
    "io.logger_setup() # run this to get printing of progress\n",
    "\n",
    "#Check if colab notebook instance has GPU access\n",
    "if core.use_gpu()==False:\n",
    "  raise ImportError(\"No GPU access, change your runtime\")\n",
    "\n",
    "model = models.CellposeModel(gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 images in folder:\n",
      "8hr_BTZ_image1.tif\n",
      "just_two_channel.tif\n",
      "tif_deneme_1.tif\n"
     ]
    }
   ],
   "source": [
    "# *** change to your google drive folder path ***\n",
    "dir = \"/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/input/\"\n",
    "dir = Path(dir)\n",
    "if not dir.exists():\n",
    "  raise FileNotFoundError(\"directory does not exist\")\n",
    "\n",
    "# *** change to your image extension ***\n",
    "image_ext = \".tif\"\n",
    "\n",
    "# list all files\n",
    "files = natsorted([f for f in dir.glob(\"*\"+image_ext) if \"_masks\" not in f.name and \"_flows\" not in f.name])\n",
    "\n",
    "if(len(files)==0):\n",
    "  raise FileNotFoundError(\"no image files found, did you specify the correct folder and extension?\")\n",
    "else:\n",
    "  print(f\"{len(files)} images in folder:\")\n",
    "\n",
    "for f in files:\n",
    "  print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:42:27,803 [INFO] reading tiff with 36 planes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 527.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:42:27,876 [INFO] multi-stack tiff read in as having 9 planes 4 channels\n",
      "2025-05-06 15:42:27,909 [WARNING] WARNING: more than 2 channels given, use 'channels' input for specifying channels - just using first 2 channels to run processing\n",
      "2025-05-06 15:42:27,910 [WARNING] normalize_params['norm3D'] is True but do_3D is False and stitch_threshold=0, so setting to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-06 15:42:28,139 [INFO] 0%|          | 0/9 [00:00<?, ?it/s]\n",
      "2025-05-06 15:42:49,829 [INFO] 100%|##########| 9/9 [00:21<00:00,  2.41s/it]\n",
      "2025-05-06 15:42:49,879 [INFO] network run in 21.74s\n",
      "2025-05-06 15:42:49,884 [INFO] 0%|          | 0/9 [00:00<?, ?it/s]\n",
      "2025-05-06 15:42:49,914 [INFO] No cell pixels found.\n",
      "2025-05-06 15:42:50,527 [WARNING] no seeds found in get_masks_torch - no masks found.\n",
      "2025-05-06 15:42:50,562 [INFO] No cell pixels found.\n",
      "2025-05-06 15:42:50,591 [INFO] No cell pixels found.\n",
      "2025-05-06 15:42:50,763 [WARNING] no seeds found in get_masks_torch - no masks found.\n",
      "2025-05-06 15:42:50,877 [WARNING] no seeds found in get_masks_torch - no masks found.\n",
      "2025-05-06 15:42:50,996 [WARNING] no seeds found in get_masks_torch - no masks found.\n",
      "2025-05-06 15:42:51,112 [WARNING] no seeds found in get_masks_torch - no masks found.\n",
      "2025-05-06 15:42:51,340 [INFO] 100%|##########| 9/9 [00:01<00:00,  6.19it/s]\n",
      "2025-05-06 15:42:51,341 [WARNING] 3D stack used, but stitch_threshold=0 and do_3D=False, so masks are made per plane only\n",
      "2025-05-06 15:42:51,341 [INFO] masks created in 1.46s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (9, 4, 1024, 1024) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/sam.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/sam.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m masks, flows, styles \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval(img, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, flow_threshold\u001b[39m=\u001b[39mflow_threshold, cellprob_threshold\u001b[39m=\u001b[39mcellprob_threshold,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/sam.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                   normalize\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtile_norm_blocksize\u001b[39m\u001b[39m\"\u001b[39m: tile_norm_blocksize})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/sam.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/sam.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m plot\u001b[39m.\u001b[39;49mshow_segmentation(fig, img, masks, flows[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/sam.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/demir/Documents/Hva_AI/afstudeerproject/codes_yunus/sam.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/napari-env/lib/python3.10/site-packages/cellpose/plot.py:76\u001b[0m, in \u001b[0;36mshow_segmentation\u001b[0;34m(fig, img, maski, flowi, channels, file_name)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m img0\u001b[39m.\u001b[39mmax() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m50.0\u001b[39m:\n\u001b[1;32m     75\u001b[0m         img0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39muint8(np\u001b[39m.\u001b[39mclip(img0, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m ax\u001b[39m.\u001b[39;49mimshow(img0)\n\u001b[1;32m     77\u001b[0m ax\u001b[39m.\u001b[39mset_title(\u001b[39m\"\u001b[39m\u001b[39moriginal image\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m ax\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/napari-env/lib/python3.10/site-packages/matplotlib/__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1519\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1520\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1521\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\n\u001b[1;32m   1522\u001b[0m             ax,\n\u001b[1;32m   1523\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(cbook\u001b[39m.\u001b[39;49msanitize_sequence, args),\n\u001b[1;32m   1524\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: cbook\u001b[39m.\u001b[39;49msanitize_sequence(v) \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems()})\n\u001b[1;32m   1526\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1527\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1528\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/napari-env/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5976\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5973\u001b[0m \u001b[39mif\u001b[39;00m aspect \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5976\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5977\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5978\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5979\u001b[0m     \u001b[39m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/napari-env/lib/python3.10/site-packages/matplotlib/image.py:685\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(A, PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mImage):\n\u001b[1;32m    684\u001b[0m     A \u001b[39m=\u001b[39m pil_to_array(A)  \u001b[39m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_normalize_image_array(A)\n\u001b[1;32m    686\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_imcache \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/napari-env/lib/python3.10/site-packages/matplotlib/image.py:653\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    651\u001b[0m     A \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> 653\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{\u001b[39;00mA\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    655\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    658\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    659\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (9, 4, 1024, 1024) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = io.imread(files[2])\n",
    "print(img.shape)\n",
    "\n",
    "flow_threshold = 0.4\n",
    "cellprob_threshold = 0.0\n",
    "tile_norm_blocksize = 0\n",
    "\n",
    "masks, flows, styles = model.eval(img, batch_size=32, \n",
    "                                  flow_threshold=flow_threshold, \n",
    "                                  cellprob_threshold=cellprob_threshold, \n",
    "                                  diameter=100,\n",
    "                                  normalize={\"tile_norm_blocksize\": tile_norm_blocksize})\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plot.show_segmentation(fig, img, masks, flows[0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
